{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-12T12:58:51.439629Z",
     "start_time": "2025-01-12T12:58:51.434431Z"
    }
   },
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gower\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "4c3f1d02d6533215",
   "metadata": {},
   "source": [
    "Setting the seed to get reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "id": "de780621e10cc5d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T12:58:51.462694Z",
     "start_time": "2025-01-12T12:58:51.457114Z"
    }
   },
   "source": [
    "np.random.seed(123)"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "id": "5d93becd8dff7f0e",
   "metadata": {},
   "source": [
    "Data preparation. Reading the data in from file, merging the headers into one line, splitting the data into X and Y sets, and into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "id": "9d493a9be3b10358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T12:58:54.836676Z",
     "start_time": "2025-01-12T12:58:51.626758Z"
    }
   },
   "source": [
    "headers = pd.read_csv(\"./data/tracks.csv\", nrows = 3, header = None, sep=\",\")\n",
    "combined_headers = headers.apply(lambda x: '.'.join(x.dropna().astype(str)), axis=0)\n",
    "df = pd.read_csv(\"./data/tracks.csv\", skiprows = 3, header = None, sep=\",\")\n",
    "df.columns = combined_headers\n",
    "print(headers)\n",
    "\n",
    "df.drop(columns=[\"album.comments\", \"album.id\", \"album.information\", \"album.engineer\", \"artist.bio\", \"artist.comments\", \"artist.latitude\", \"artist.longitude\", \"artist.related_projects\", \"artist.website\", \"artist.wikipedia_page\", \"set.split\", \"set.subset\", \"track.information\", \"track.lyricist\", \"track.interest\", \"track.license\", \"track.number\", \"track.bit_rate\"], inplace=True)\n",
    "\n",
    "X = df.iloc[: ,1:]\n",
    "Y = df.iloc[:, :1]\n",
    "\n",
    "X_train,X_test,y_test,y_train = train_test_split(X,Y,test_size= 0.2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1             2              3         4          5   \\\n",
      "0       NaN     album         album          album     album      album   \n",
      "1       NaN  comments  date_created  date_released  engineer  favorites   \n",
      "2  track_id       NaN           NaN            NaN       NaN        NaN   \n",
      "\n",
      "      6            7        8         9   ...           43        44  \\\n",
      "0  album        album    album     album  ...        track     track   \n",
      "1     id  information  listens  producer  ...  information  interest   \n",
      "2    NaN          NaN      NaN       NaN  ...          NaN       NaN   \n",
      "\n",
      "              45       46       47        48      49         50     51     52  \n",
      "0          track    track    track     track   track      track  track  track  \n",
      "1  language_code  license  listens  lyricist  number  publisher   tags  title  \n",
      "2            NaN      NaN      NaN       NaN     NaN        NaN    NaN    NaN  \n",
      "\n",
      "[3 rows x 53 columns]\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "40ebafc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T12:58:54.996686Z",
     "start_time": "2025-01-12T12:58:54.990389Z"
    }
   },
   "source": [
    "# Retrieve query from the user\n",
    "def get_user_query(df):\n",
    "    print(\"Enter the attributes of the query as comma-separated values:\")\n",
    "    query_input = input()\n",
    "    try:\n",
    "        # Split input and convert to match DataFrame structure\n",
    "        query_data = [float(x) if x.replace('.', '', 1).isdigit() else x for x in query_input.split(\",\")]\n",
    "        query_df = pd.DataFrame([query_data], columns=df.columns)\n",
    "        return query_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing query: {e}\")\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "id": "d5fd21c7f33d0b4",
   "metadata": {},
   "source": [
    "Query retrieval, and running the Gower distance algorithm on the data "
   ]
  },
  {
   "cell_type": "code",
   "id": "9df4556da9638a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T12:59:01.582047Z",
     "start_time": "2025-01-12T12:58:55.143637Z"
    }
   },
   "source": [
    "\n",
    "query = get_user_query(X) \n",
    "if query is None:\n",
    "    query = X.iloc[0:1]\n",
    "    \n",
    "distances = gower.gower_matrix(X, query)\n",
    "\n",
    "print(distances)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the attributes of the query as comma-separated values:\n",
      "Error processing query: 33 columns passed, passed data had 1 columns\n",
      "[[0.15151516]\n",
      " [0.21229906]\n",
      " [0.21227367]\n",
      " ...\n",
      " [0.66944236]\n",
      " [0.6691228 ]\n",
      " [0.7257222 ]]\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "id": "9335468ca4889437",
   "metadata": {},
   "source": [
    "Ranking rows in the DataFrame according to their proximity to the query. Excluding the 1st record from the closest_indices list, since it is an id of the record from the query\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fb052fd0a7d092ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T12:59:01.758661Z",
     "start_time": "2025-01-12T12:59:01.731599Z"
    }
   },
   "source": [
    "distances = np.nan_to_num(distances, nan=np.inf)\n",
    "distances = distances.flatten()\n",
    "\n",
    "\n",
    "closest_indices = np.argsort(distances)[1:10001]\n",
    "print(closest_indices)\n",
    "\n",
    "print(df.iloc[closest_indices])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    9     2     1 ... 12297 12348 12769]\n",
      "       track_id   album.date_created  album.date_released  album.favorites  \\\n",
      "9           134  2008-11-26 01:44:45  2009-01-05 00:00:00                4   \n",
      "2             5  2008-11-26 01:44:45  2009-01-05 00:00:00                4   \n",
      "1             3  2008-11-26 01:44:45  2009-01-05 00:00:00                4   \n",
      "5846      10815  2008-11-26 01:44:45  2009-01-05 00:00:00                4   \n",
      "5729      10666  2008-11-26 01:44:45  2009-01-05 00:00:00                4   \n",
      "...         ...                  ...                  ...              ...   \n",
      "12193     19965  2009-10-22 08:34:13  2005-08-02 00:00:00                0   \n",
      "12910     20996  2009-11-12 18:47:07                  NaN                1   \n",
      "12297     20081  2009-10-27 03:36:05  2009-10-18 00:00:00                0   \n",
      "12348     20136  2009-10-28 08:02:51                  NaN                0   \n",
      "12769     20831  2009-11-12 05:23:00                  NaN                0   \n",
      "\n",
      "       album.listens album.producer album.tags  \\\n",
      "9               6073            NaN         []   \n",
      "2               6073            NaN         []   \n",
      "1               6073            NaN         []   \n",
      "5846            6073            NaN         []   \n",
      "5729            6073            NaN         []   \n",
      "...              ...            ...        ...   \n",
      "12193            212            NaN         []   \n",
      "12910           1681            NaN         []   \n",
      "12297          18086            NaN         []   \n",
      "12348          19699            NaN         []   \n",
      "12769           7840            NaN         []   \n",
      "\n",
      "                                       album.title  album.tracks album.type  \\\n",
      "9                             AWOL - A Way Of Life             7      Album   \n",
      "2                             AWOL - A Way Of Life             7      Album   \n",
      "1                             AWOL - A Way Of Life             7      Album   \n",
      "5846                          AWOL - A Way Of Life             7      Album   \n",
      "5729                          AWOL - A Way Of Life             7      Album   \n",
      "...                                            ...           ...        ...   \n",
      "12193                            Through the Smoke             1      Album   \n",
      "12910        Live at ISSUE Project Room (11/11/09)             4      Album   \n",
      "12297                               Kallokontrolli            24      Album   \n",
      "12348  Antique Phonograph Music Program 03/30/1999            15      Album   \n",
      "12769            Dark Cabinet of the Strange Weird            11      Album   \n",
      "\n",
      "       ... track.duration track.favorites      track.genre_top  \\\n",
      "9      ...            207               3              Hip-Hop   \n",
      "2      ...            206               6              Hip-Hop   \n",
      "1      ...            237               1              Hip-Hop   \n",
      "5846   ...            151               3              Hip-Hop   \n",
      "5729   ...            266               2              Hip-Hop   \n",
      "...    ...            ...             ...                  ...   \n",
      "12193  ...            391               1                 Rock   \n",
      "12910  ...            711               5                  NaN   \n",
      "12297  ...            388               2                  NaN   \n",
      "12348  ...            198               0  Old-Time / Historic   \n",
      "12769  ...            275               0                  NaN   \n",
      "\n",
      "                 track.genres                  track.genres_all  \\\n",
      "9                        [21]                              [21]   \n",
      "2                        [21]                              [21]   \n",
      "1                        [21]                              [21]   \n",
      "5846                     [21]                              [21]   \n",
      "5729                     [21]                              [21]   \n",
      "...                       ...                               ...   \n",
      "12193                [36, 58]                      [58, 36, 12]   \n",
      "12910          [97, 125, 250]             [97, 4, 38, 250, 125]   \n",
      "12297  [15, 32, 47, 107, 247]  [32, 38, 107, 47, 15, 1235, 247]   \n",
      "12348                     [8]                               [8]   \n",
      "12769                [1, 138]                  [1, 138, 20, 38]   \n",
      "\n",
      "       track.language_code track.listens track.publisher track.tags  \\\n",
      "9                       en           943             NaN         []   \n",
      "2                       en          1151             NaN         []   \n",
      "1                       en           514             NaN         []   \n",
      "5846                    en          1205             NaN         []   \n",
      "5729                    en           929             NaN         []   \n",
      "...                    ...           ...             ...        ...   \n",
      "12193                   en           212             NaN         []   \n",
      "12910                   en          1065             NaN         []   \n",
      "12297                   en           905             NaN         []   \n",
      "12348                   en          1167             NaN         []   \n",
      "12769                   en           172             NaN         []   \n",
      "\n",
      "                             track.title  \n",
      "9                           Street Music  \n",
      "2                             This World  \n",
      "1                           Electric Ave  \n",
      "5846                               CYCLE  \n",
      "5729                           Hangloose  \n",
      "...                                  ...  \n",
      "12193                            Vibe #6  \n",
      "12910                         @ ISSUE II  \n",
      "12297  210-Ruttopuiston kaveleva vainaja  \n",
      "12348                Cohen At the Movies  \n",
      "12769           Crystal Skull of Lemuria  \n",
      "\n",
      "[10000 rows x 34 columns]\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "id": "69fd058d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T12:59:03.815009Z",
     "start_time": "2025-01-12T12:59:02.048405Z"
    }
   },
   "source": [
    "# Pre-trained light weight model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Combining textual columns for S-BERT\n",
    "textual_data = (df['track.title'] + \" \" + df['track.information']).fillna(\"\")\n",
    "query_text = (str(query['track.title'].iloc[0]) + \" \" + str(query['track.information'].iloc[0])).strip()\n",
    "\n",
    "# Computing embeddings\n",
    "text_embeddings = model.encode(textual_data.tolist())\n",
    "query_embedding = model.encode([query_text])"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'track.information'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'track.information'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[54], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m SentenceTransformer(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall-MiniLM-L6-v2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Combining textual columns for S-BERT\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m textual_data \u001B[38;5;241m=\u001B[39m (df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrack.title\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrack.information\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mfillna(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      6\u001B[0m query_text \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mstr\u001B[39m(query[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrack.title\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(query[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrack.information\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m0\u001B[39m]))\u001B[38;5;241m.\u001B[39mstrip()\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Computing embeddings\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[0;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3810\u001B[0m     ):\n\u001B[0;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'track.information'"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "id": "f9c5ced2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T12:59:03.820228800Z",
     "start_time": "2025-01-12T12:18:18.223183Z"
    }
   },
   "source": [
    "# Filter dataset using closest_indices from Gower\n",
    "filtered_embeddings = text_embeddings[closest_indices]\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity_scores = cosine_similarity(query_embedding, filtered_embeddings).flatten()\n",
    "\n",
    "# Get the top N results\n",
    "top_indices = np.argsort(similarity_scores)[::-1][:10]\n",
    "final_indices = [closest_indices[i] for i in top_indices]"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "25b2b838",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T12:59:03.820228800Z",
     "start_time": "2025-01-12T12:18:18.682202Z"
    }
   },
   "source": [
    "# Retrieve recommendations\n",
    "recommendations = df.iloc[final_indices]\n",
    "print(recommendations[['track.title', 'track.information', 'artist.name']])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            track.title  \\\n",
      "17926                                     Eating Babies   \n",
      "2191       Turning Dance and Fast Csardas from Bonchida   \n",
      "28829                  Steak and Acid/Claudette colbert   \n",
      "1891                   How Much Pudding Can Tomy Handle   \n",
      "4426                              Neptune Sunset Casino   \n",
      "3232   Shitlife (Retrigger Rotuque mix) ft. Don Augusto   \n",
      "6783     Melting Your Brains (featuring the DRUM BUDDY)   \n",
      "1862                                           No Coins   \n",
      "1793                                    Puddin' and Pie   \n",
      "1820                                    Penny and Jenny   \n",
      "\n",
      "                                       track.information  \\\n",
      "17926  <p>Eating Babies is from the album Death Face,...   \n",
      "2191   <p>Effusive thanks to: Veronica Liu (board op)...   \n",
      "28829  <p>From 'Music for meditation relaxation and t...   \n",
      "1891   <p><span style=\"margin: 0pt 5px; float: left;\"...   \n",
      "4426                   <P>Based on Thai Molam style.</P>   \n",
      "3232                         <p>This is information.</p>   \n",
      "6783   <p>This song features Mattress Fox on second v...   \n",
      "1862   <p><a href=\"http://wfmu.org/playlists/LB\">Liz ...   \n",
      "1793   <p><span style=\"font-family: Verdana,Geneva,Ar...   \n",
      "1820   <p><span style=\"font-family: Verdana,Geneva,Ar...   \n",
      "\n",
      "                 artist.name  \n",
      "17926           Grave Babies  \n",
      "2191               MetroFolk  \n",
      "28829  Kreamy 'Lectric Santa  \n",
      "1891              Dan Deacon  \n",
      "4426         Hayvanlar Alemi  \n",
      "3232               Retrigger  \n",
      "6783       Bermuda Triangles  \n",
      "1862              Cryptacize  \n",
      "1793             Byron Coley  \n",
      "1820              Cheap Time  \n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
